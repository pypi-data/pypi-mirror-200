{
  "ADDITIONAL_OPTIONS": {
    "bool_opt": {
      "desc": "A boolean option",
      "value": true,
      "type": "bool"
    },
    "int_opt": {
      "desc": "An integer option",
      "value": 42,
      "type": "int"
    },
    "float_opt": {
      "desc": "A float option",
      "value": 3.14,
      "type": "float"
    },
    "string_opt": {
      "desc": "A string option",
      "value": "Hello World",
      "type": "string"
    },
    "list_opt": {
      "desc": "A list option",
      "value": [
        "Hello",
        "World"
      ],
      "type": "list"
    },
    "text_opt": {
      "desc": "A text option",
      "value": "Hello\nWorld",
      "type": "text"
    },
    "auto_opt": {
      "desc": "An auto option",
      "value": {},
      "type": "auto"
    },
    "ns_opt": {
      "desc": "A namespace option",
      "type": "namespace",
      "value": {
        "nest_opt": {
          "desc": "A nested ns option",
          "type": "namespace",
          "value": {
            "x": {
              "desc": "An option of a nested ns option",
              "value": 1,
              "itype": "int",
              "type": "choice",
              "choices": [
                1,
                2,
                3
              ],
              "choices_desc": [
                "One",
                "Two",
                "Three"
              ]
            }
          }
        },
        "y": {
          "desc": "Another option of a ns option",
          "order": -1,
          "value": [
            1.0,
            2.0,
            3.0
          ],
          "itype": "float",
          "type": "mchoices",
          "choices": [
            1.0,
            2.0,
            3.0,
            4.0,
            5.0
          ],
          "choices_desc": [
            "One",
            "Two",
            "Three",
            "Four",
            "Five"
          ]
        }
      }
    }
  },
  "RUNNING_OPTIONS": {
    "Local": {
      "desc": "The options for running the pipeline locally",
      "command": "python -m pipeline @${configfile} --datadir ${datadir}",
      "value": {
        "configfile": {
          "desc": "The configuration file for the pipeline, typically generated by this wizard\n",
          "required": true,
          "value": "config.toml",
          "placeholder": "config.toml"
        },
        "datadir": {
          "desc": "The directory where the data is stored",
          "required": true,
          "value": ""
        }
      }
    }
  },
  "PIPELINE_OPTIONS": {
    "loglevel": {
      "type": "choice",
      "choices": [
        "debug",
        "info",
        "warning",
        "error",
        "critical"
      ],
      "value": "info",
      "hidden": true,
      "desc": "Logging level. This affects the log level of the main plugin."
    },
    "cache": {
      "type": "auto",
      "value": null,
      "placeholder": "true",
      "hidden": true,
      "desc": "# Job caching\n\nIf cache set to False (detected in the sequence of configuration files,\nPipen constructor, and process definition), the job is running anyway\nregardless of previous runs.\n\nIf a previous run of a job fails, the job will be running anyway.\n\nIf a job is done successfully, a signature file will be generated for\nthe job. When we try to run the job again, the signature will be used\nto check if we can skip running the job again but to use the results\ngenerated by previous run.\n\nWe can also do a force-cache for a job by setting cache to \"force\".\nThis make sure of the results of previous successful run regardless of\ninput or script changes. This is useful for the cases that, for example,\nyou make some changes to input/script, but you don't want them to take\neffect immediately, especially when the job takes long time to run.\n"
    },
    "num_retries": {
      "type": "int",
      "placeholder": "3",
      "value": null,
      "hidden": true,
      "desc": "Number of retries when a job fails. "
    },
    "submission_batch": {
      "type": "int",
      "placeholder": "8",
      "value": null,
      "hidden": true,
      "desc": "Number of jobs to submit at a time"
    },
    "scheduler": {
      "placeholder": "local",
      "value": null,
      "hidden": true,
      "desc": "The scheduler to use"
    },
    "scheduler_opts": {
      "desc": "The scheduler options",
      "value": {
        "<option_name>": {
          "type": "auto",
          "desc": "The value of the option"
        }
      }
    },
    "plugin_opts": {
      "desc": "The plugin options of your pipeline",
      "value": {
        "<plugin_name>_<plugin_opt_name>": {
          "desc": "The value of plugin option `<plugin_name>_<plugin_opt_name>`",
          "type": "str"
        }
      }
    },
    "forks": {
      "type": "int",
      "placeholder": "1",
      "value": null,
      "desc": "Number of jobs to run in parallel for each process\n\nThe ability to run multiple jobs in parallel is provided by the the scheduler\nsystem. For example, if you use the local scheduler, the jobs will be run in\nparallel using the `multiprocessing` module. If you use the `sge` scheduler,\nthe jobs will be submitted to the slurm scheduler and run in parallel.\n"
    },
    "dirsig": {
      "type": "int",
      "placeholder": "1",
      "value": null,
      "hidden": true,
      "desc": "How deep we should go to check directory signature"
    },
    "error_strategy": {
      "type": "choice",
      "choices": [
        "ignore",
        "retry",
        "halk"
      ],
      "choices_desc": [
        "Ignore the error and continue to run next jobs",
        "Retry the job",
        "Halt the pipeline"
      ],
      "value": "ignore",
      "desc": "What to do when a job fails",
      "hidden": true
    },
    "name": {
      "type": "str",
      "value": "ExamplePipeline",
      "placeholder": "ExamplePipeline",
      "cached_file": "example-example-py-examplepipeline.json",
      "desc": "The name of the pipeline. It will affect the names of working directory and the result directory"
    },
    "desc": {
      "type": "str",
      "value": "An example pipeline showing how pipen-cli-config works.",
      "desc": "The description of the pipeline, shows in the log and report."
    },
    "outdir": {
      "desc": "The output directory of your pipeline",
      "placeholder": "./<name>_results",
      "type": "str",
      "value": null
    }
  },
  "PROCESSES": {
    "P1": {
      "is_start": true,
      "desc": "# The P1 process\n\n",
      "value": {
        "in": {
          "desc": "The input data for the process",
          "type": "ns",
          "value": {
            "invar": {
              "itype": "var",
              "required": true,
              "nargs": "+",
              "action": "extend",
              "type": "list",
              "value": null,
              "desc": "The input variable"
            }
          }
        },
        "envs": {
          "desc": "Environment variables for the process, used across jobs",
          "value": {}
        },
        "plugin_opts": {
          "desc": "The plugin options of your pipeline",
          "value": {
            "<plugin_name>_<plugin_opt_name>": {
              "desc": "The value of plugin option `<plugin_name>_<plugin_opt_name>`",
              "type": "str"
            }
          }
        },
        "scheduler_opts": {
          "desc": "The scheduler options",
          "value": {
            "<option_name>": {
              "type": "auto",
              "desc": "The value of the option"
            }
          }
        },
        "forks": {
          "type": "int",
          "placeholder": "1",
          "value": null,
          "desc": "Number of jobs to run in parallel for each process\n\nThe ability to run multiple jobs in parallel is provided by the the scheduler\nsystem. For example, if you use the local scheduler, the jobs will be run in\nparallel using the `multiprocessing` module. If you use the `sge` scheduler,\nthe jobs will be submitted to the slurm scheduler and run in parallel.\n"
        },
        "cache": {
          "type": "auto",
          "value": null,
          "placeholder": "true",
          "hidden": true,
          "desc": "# Job caching\n\nIf cache set to False (detected in the sequence of configuration files,\nPipen constructor, and process definition), the job is running anyway\nregardless of previous runs.\n\nIf a previous run of a job fails, the job will be running anyway.\n\nIf a job is done successfully, a signature file will be generated for\nthe job. When we try to run the job again, the signature will be used\nto check if we can skip running the job again but to use the results\ngenerated by previous run.\n\nWe can also do a force-cache for a job by setting cache to \"force\".\nThis make sure of the results of previous successful run regardless of\ninput or script changes. This is useful for the cases that, for example,\nyou make some changes to input/script, but you don't want them to take\neffect immediately, especially when the job takes long time to run.\n"
        },
        "scheduler": {
          "placeholder": "local",
          "value": null,
          "hidden": true,
          "desc": "The scheduler to use"
        },
        "dirsig": {
          "type": "int",
          "placeholder": "1",
          "value": null,
          "hidden": true,
          "desc": "How deep we should go to check directory signature"
        },
        "error_strategy": {
          "type": "choice",
          "choices": [
            "ignore",
            "retry",
            "halk"
          ],
          "choices_desc": [
            "Ignore the error and continue to run next jobs",
            "Retry the job",
            "Halt the pipeline"
          ],
          "value": "ignore",
          "desc": "What to do when a job fails",
          "hidden": true
        },
        "num_retries": {
          "type": "int",
          "placeholder": "3",
          "value": null,
          "hidden": true,
          "desc": "Number of retries when a job fails. "
        },
        "lang": {
          "desc": "The interpreter to run the script",
          "hidden": true,
          "placeholder": null,
          "value": null
        }
      }
    },
    "P4": {
      "is_start": false,
      "desc": "# The P4 process\n\n",
      "value": {
        "envs": {
          "desc": "Environment variables for the process, used across jobs",
          "value": {
            "abc": {
              "value": "123",
              "desc": "The abc env"
            },
            "method": {
              "ns": true,
              "type": "ns",
              "value": {
                "a": {
                  "value": 1,
                  "desc": "Use method a"
                },
                "b": {
                  "value": null,
                  "desc": "Use method b"
                },
                "c": {
                  "value": null,
                  "desc": "Use method c"
                }
              },
              "desc": "The method to use.\nMore description about method.\n>>> code code code code code code code code code code code code code code code code code code code code\n>>> more code"
            }
          }
        },
        "plugin_opts": {
          "desc": "The plugin options of your pipeline",
          "value": {
            "<plugin_name>_<plugin_opt_name>": {
              "desc": "The value of plugin option `<plugin_name>_<plugin_opt_name>`",
              "type": "str"
            }
          }
        },
        "scheduler_opts": {
          "desc": "The scheduler options",
          "value": {
            "<option_name>": {
              "type": "auto",
              "desc": "The value of the option"
            }
          }
        },
        "forks": {
          "type": "int",
          "placeholder": "1",
          "value": null,
          "desc": "Number of jobs to run in parallel for each process\n\nThe ability to run multiple jobs in parallel is provided by the the scheduler\nsystem. For example, if you use the local scheduler, the jobs will be run in\nparallel using the `multiprocessing` module. If you use the `sge` scheduler,\nthe jobs will be submitted to the slurm scheduler and run in parallel.\n"
        },
        "cache": {
          "type": "auto",
          "value": null,
          "placeholder": "true",
          "hidden": true,
          "desc": "# Job caching\n\nIf cache set to False (detected in the sequence of configuration files,\nPipen constructor, and process definition), the job is running anyway\nregardless of previous runs.\n\nIf a previous run of a job fails, the job will be running anyway.\n\nIf a job is done successfully, a signature file will be generated for\nthe job. When we try to run the job again, the signature will be used\nto check if we can skip running the job again but to use the results\ngenerated by previous run.\n\nWe can also do a force-cache for a job by setting cache to \"force\".\nThis make sure of the results of previous successful run regardless of\ninput or script changes. This is useful for the cases that, for example,\nyou make some changes to input/script, but you don't want them to take\neffect immediately, especially when the job takes long time to run.\n"
        },
        "scheduler": {
          "placeholder": "local",
          "value": null,
          "hidden": true,
          "desc": "The scheduler to use"
        },
        "dirsig": {
          "type": "int",
          "placeholder": "1",
          "value": null,
          "hidden": true,
          "desc": "How deep we should go to check directory signature"
        },
        "error_strategy": {
          "type": "choice",
          "choices": [
            "ignore",
            "retry",
            "halk"
          ],
          "choices_desc": [
            "Ignore the error and continue to run next jobs",
            "Retry the job",
            "Halt the pipeline"
          ],
          "value": "ignore",
          "desc": "What to do when a job fails",
          "hidden": true
        },
        "num_retries": {
          "type": "int",
          "placeholder": "3",
          "value": null,
          "hidden": true,
          "desc": "Number of retries when a job fails. "
        },
        "lang": {
          "desc": "The interpreter to run the script",
          "hidden": true,
          "placeholder": null,
          "value": null
        }
      }
    }
  },
  "PROCGROUPS": {
    "MyGroup": {
      "PROCESSES": {
        "P2": {
          "is_start": false,
          "desc": "# Undescribed process.\n\n",
          "value": {
            "envs": {
              "desc": "Environment variables for the process, used across jobs",
              "value": {}
            },
            "plugin_opts": {
              "desc": "The plugin options of your pipeline",
              "value": {
                "<plugin_name>_<plugin_opt_name>": {
                  "desc": "The value of plugin option `<plugin_name>_<plugin_opt_name>`",
                  "type": "str"
                }
              }
            },
            "scheduler_opts": {
              "desc": "The scheduler options",
              "value": {
                "<option_name>": {
                  "type": "auto",
                  "desc": "The value of the option"
                }
              }
            },
            "forks": {
              "type": "int",
              "placeholder": "1",
              "value": null,
              "desc": "Number of jobs to run in parallel for each process\n\nThe ability to run multiple jobs in parallel is provided by the the scheduler\nsystem. For example, if you use the local scheduler, the jobs will be run in\nparallel using the `multiprocessing` module. If you use the `sge` scheduler,\nthe jobs will be submitted to the slurm scheduler and run in parallel.\n"
            },
            "cache": {
              "type": "auto",
              "value": null,
              "placeholder": "true",
              "hidden": true,
              "desc": "# Job caching\n\nIf cache set to False (detected in the sequence of configuration files,\nPipen constructor, and process definition), the job is running anyway\nregardless of previous runs.\n\nIf a previous run of a job fails, the job will be running anyway.\n\nIf a job is done successfully, a signature file will be generated for\nthe job. When we try to run the job again, the signature will be used\nto check if we can skip running the job again but to use the results\ngenerated by previous run.\n\nWe can also do a force-cache for a job by setting cache to \"force\".\nThis make sure of the results of previous successful run regardless of\ninput or script changes. This is useful for the cases that, for example,\nyou make some changes to input/script, but you don't want them to take\neffect immediately, especially when the job takes long time to run.\n"
            },
            "scheduler": {
              "placeholder": "local",
              "value": null,
              "hidden": true,
              "desc": "The scheduler to use"
            },
            "dirsig": {
              "type": "int",
              "placeholder": "1",
              "value": null,
              "hidden": true,
              "desc": "How deep we should go to check directory signature"
            },
            "error_strategy": {
              "type": "choice",
              "choices": [
                "ignore",
                "retry",
                "halk"
              ],
              "choices_desc": [
                "Ignore the error and continue to run next jobs",
                "Retry the job",
                "Halt the pipeline"
              ],
              "value": "ignore",
              "desc": "What to do when a job fails",
              "hidden": true
            },
            "num_retries": {
              "type": "int",
              "placeholder": "3",
              "value": null,
              "hidden": true,
              "desc": "Number of retries when a job fails. "
            },
            "lang": {
              "desc": "The interpreter to run the script",
              "hidden": true,
              "placeholder": "bash",
              "value": null
            }
          }
        },
        "P3": {
          "is_start": false,
          "desc": "# Undescribed process.\n\n",
          "value": {
            "envs": {
              "desc": "Environment variables for the process, used across jobs",
              "value": {}
            },
            "plugin_opts": {
              "desc": "The plugin options of your pipeline",
              "value": {
                "<plugin_name>_<plugin_opt_name>": {
                  "desc": "The value of plugin option `<plugin_name>_<plugin_opt_name>`",
                  "type": "str"
                }
              }
            },
            "scheduler_opts": {
              "desc": "The scheduler options",
              "value": {
                "<option_name>": {
                  "type": "auto",
                  "desc": "The value of the option"
                }
              }
            },
            "forks": {
              "type": "int",
              "placeholder": "1",
              "value": null,
              "desc": "Number of jobs to run in parallel for each process\n\nThe ability to run multiple jobs in parallel is provided by the the scheduler\nsystem. For example, if you use the local scheduler, the jobs will be run in\nparallel using the `multiprocessing` module. If you use the `sge` scheduler,\nthe jobs will be submitted to the slurm scheduler and run in parallel.\n"
            },
            "cache": {
              "type": "auto",
              "value": null,
              "placeholder": "true",
              "hidden": true,
              "desc": "# Job caching\n\nIf cache set to False (detected in the sequence of configuration files,\nPipen constructor, and process definition), the job is running anyway\nregardless of previous runs.\n\nIf a previous run of a job fails, the job will be running anyway.\n\nIf a job is done successfully, a signature file will be generated for\nthe job. When we try to run the job again, the signature will be used\nto check if we can skip running the job again but to use the results\ngenerated by previous run.\n\nWe can also do a force-cache for a job by setting cache to \"force\".\nThis make sure of the results of previous successful run regardless of\ninput or script changes. This is useful for the cases that, for example,\nyou make some changes to input/script, but you don't want them to take\neffect immediately, especially when the job takes long time to run.\n"
            },
            "scheduler": {
              "placeholder": "local",
              "value": null,
              "hidden": true,
              "desc": "The scheduler to use"
            },
            "dirsig": {
              "type": "int",
              "placeholder": "1",
              "value": null,
              "hidden": true,
              "desc": "How deep we should go to check directory signature"
            },
            "error_strategy": {
              "type": "choice",
              "choices": [
                "ignore",
                "retry",
                "halk"
              ],
              "choices_desc": [
                "Ignore the error and continue to run next jobs",
                "Retry the job",
                "Halt the pipeline"
              ],
              "value": "ignore",
              "desc": "What to do when a job fails",
              "hidden": true
            },
            "num_retries": {
              "type": "int",
              "placeholder": "3",
              "value": null,
              "hidden": true,
              "desc": "Number of retries when a job fails. "
            },
            "lang": {
              "desc": "The interpreter to run the script",
              "hidden": true,
              "placeholder": null,
              "value": null
            }
          }
        }
      }
    }
  }
}